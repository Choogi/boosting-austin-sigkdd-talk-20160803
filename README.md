Materials from Austin SIGKDD talk on boosting, 8/3/16

Slides
* Mine, from the talk
  * [pptx](https://github.com/mlandry22/boosting-austin-sigkdd-talk-20160803/blob/master/Boosting-Austin-SIGKDD.pptx)
  * [PDF](https://github.com/mlandry22/boosting-austin-sigkdd-talk-20160803/blob/master/Boosting-Austin-SIGKDD.pdf)
* Scikit-learn slides, from it's author
  * [PDF](https://github.com/mlandry22/boosting-austin-sigkdd-talk-20160803/blob/master/Sklearn-Boosting-slides-140224130205-phpapp02.pdf)

H2O GBM Tuning Guide (by coworker Arno Candel)
* [blog, R markdown](http://blog.h2o.ai/2016/06/h2o-gbm-tuning-tutorial-for-r)
* [iPython notebook](https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/product/tutorials/gbm/gbmTuning.ipynb)

XGBoost Tuning Guide
* [Analytics Vidhya, cowritten by Sudalai Rajkumar](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)

XGBoost for an Analytics Vidhya competition (myself and Sudalai Rajkumar)
* [code](https://github.com/analyticsvidhya/The_Smart_Recruits/blob/master/Rank%202:%20SRK%20%26%20Mark_Model.py)
* [background article](https://www.analyticsvidhya.com/blog/2016/08/winners-approach-smart-recruits)

Kaggle Kernels (where you can run the code yourself in their own Docker images and their hardware for free)
* [Otto competition, notebook shared by XGBoost author](https://www.kaggle.com/tqchen/otto-group-product-classification-challenge/understanding-xgboost-model-on-otto-data)
* [Titanic learning competition](https://www.kaggle.com/cbrogan/titanic/xgboost-example-python)
